
## 1. Read in data and data wrangling
Let's read in the data from `Bakery_sales_data.csv` and further conduct some data manipulation.
```{r}
total_data <- read.csv("C:/MSBA 24/STAT2023/week02session02/Bakery_sales_data.csv", header=T, stringsAsFactors=T)
str(total_data)
```

We first reset the format of the `date` variable in `total_data` using `as.Date` function.
```{r}
total_data$date <- as.Date(total_data$date, format="%m/%d/%Y")
str(total_data)
```

Let's reset the reference level of the categorical variables in the data set using the `R` function `factor()` and its argument `levels`. In addition, note that the `store_id` variable in `total_data` should be categorical variable as it is an identifier of each store.
```{r}
total_data$day <- factor(total_data$day, levels=c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'))
total_data$month <- factor(total_data$month, levels=c('January','February','March','April','May','June','July',
                                                      'August','September','October','November','December'))
total_data$store_type <- factor(total_data$store_type, levels=c('rural','suburb','urban'))
total_data$store_id <- factor(total_data$store_id)
```

Data exploration and visualization
Create a scatter plot between `sales` and `promotion`. Note that `promotion` is a numerical predictor but only takes a finite number of values. Thus, let's further make a boxplot between `sales` and `promotion`, which is more informative.
```{r}

plot(total_data$sales,total_data$promotion)
boxplot(total_data$sales~total_data$promotion)
```

Create a boxplot between `sales` and `store type`. Which type of store has the highest sales on average?
```{r}

boxplot(total_data$sales~total_data$store_type)
```

Use appropriate visualization tools to investigate the relationship between `sales` and `bad_weather`, `sales` and `day`, `sales` and `month`.
```{r}

boxplot(total_data$sales~total_data$bad_weather)
boxplot(total_data$sales~total_data$day)
boxplot(total_data$sales~total_data$month)
```

Plot the histogram of `sales`. Do we need a log transformation? If so, further create a `log_sales` variable in the `R` object `total_data` using the formula $\widetilde{Y}=\log(Y+1).$
```{r}

hist(total_data$sales) # need log transformation because it is skewed 
total_data$log_sales <- log(total_data$sales+1)
hist(total_data$log_sales)
```


Linear Regression based forecasting
 Data partition
Note that for time series forecasting, data partition should respect the time order as we would like to evaluate the performance of statistical models on the most recent data. 
```{r DataPartition}
train_indices <- which(total_data$date<='2016-12-31') # We create 4 year training data and leave 1 year for test
train_data <- total_data[train_indices,]
test_data <- total_data[-train_indices,]
```

Linear regression estimation
Estimate a linear regression model with only intercept and name it `lm0`. Estimate a linear regression model with **five** predictors `store_type`, `bad_weather`, `promotion`, `day` and `month` and name it `lm_full`. Note the dependent variable should be `log_sales`.
```{r}

lm0 <- lm(log_sales~1 , data = train_data)
lm_full <- lm(log_sales~store_type + bad_weather + promotion + day + month, data = train_data)
```

What is the $R^2$ of `lm_full`? What is the impact of `bad_weather` to `log_sales` and thus to `sales`? What is the $R^2$ of `lm0`? Why? Answer:
```{r}
summary(lm_full)
summary(lm_full)$r.sq
summary(lm0)$r.sq
```
$R^2$ of `lm_full` is 0.7488, `bad_weather` has negative effect to `log_sales` and thus to `sales`. $R^2$ of `lm0` is 0. 

 Backward selection
It seems that some of the predictors are not statistically significant. First, determine the number of observations in the training data. Second, let's do a backward selection via BIC using the `step()` function and store the final selected model as `lm_bwd`. Make sure you use the **correct** number for the argument `k` in the `step()` function.
```{r}

train_num <- nrow(train_data)
lm_bwd <- step(lm_full, direction='backward', k=log(train_num))
```

What is the $R^2$ of `lm_bwd`? Which variable is removed during the backward selection?
```{r}
summary(lm_bwd)$r.sq
```
$R^2$ of `lm_bwd` is 0.7487 and variable `Month` was removed. 

 Model evaluation (out-of-sample)
Let's now evaluate the prediction performance of the three linear models `lm0`, `lm_full` and `lm_bwd` on the test data. First, let's generate the prediction by each model and store them in `pred0`, `pred_full` and `pred_bwd` respectively. Make sure to transform the prediction back to the **original** scale. We then use the `accuracy()` function from the `forecast` package to obtain the error metrics.

```{r}
# prediction of lm0
pred0 <- exp(predict(lm0, newdata=test_data))-1
# prediction of full model
pred_full <- exp(predict(lm_full, newdata=test_data))-1
# prediction of backward selected model
pred_bwd <- exp(predict(lm_bwd, newdata=test_data))-1
library(forecast)

# error of lm0
accuracy(pred0, test_data$sales)
# error of full model
accuracy(pred_full, test_data$sales)
# error of backward selected model
accuracy(pred_bwd, test_data$sales)
```

Which model should we choose and why? Judging by its performance on the test data, do you think the prediction given by linear regression is reasonably accurate?

Backward Selection model is better because it has similar accuracy as the linear model but simpler. The prediction given by linear regression is not that accurate as it has a mean error of 32. 

Visualization of the prediction on test data
To gain more intuition, let's visualize the prediction given by the linear regression `lm_bwd` on the test data and compare it with the actual observations. Specifically, let's visualize the result for the first 60 days in the test data.

```{r}

sample_time <- 1:60
plot(test_data$date[sample_time], test_data$sales[sample_time], xlab='', ylab='sales')
lines(test_data$date[sample_time], test_data$sales[sample_time])
lines(test_data$date[sample_time], pred_bwd[sample_time], col='red')
```



Rerun the above analysis with the original scale `sales`. Name the corresponding `R` objects as `lm_full1` and `lm_bwd1`. What is the test data error for `lm_full1` and `lm_bwd1`? Does log transformation help improve the forecasting accuracy?
```{r Optional Exercise}
lm_full1 <- lm(sales~store_type+bad_weather+promotion+day+month, data=train_data)
lm_bwd1 <- step(lm_full1, direction='backward', k=log(train_num))
pred_full1 <- predict(lm_full1, newdata=test_data)
pred_bwd1 <- predict(lm_bwd1, newdata=test_data)

accuracy(pred_full1, test_data$sales)
accuracy(pred_bwd1, test_data$sales)
```


Inventory planning with asymmetric revenue and loss 
The ultimate goal for demand forecasting is to decide the optimal inventory level that maximizes the **profit**. Following the notation in the lecture notes.

**Exercise 11** Suppose $r=\$10, l=\$1$, what is the optimal inventory level? Answer: `r (10-1)/10` quantile of the future sales.

```{r profit function}
# This is a customized function to evaluate the profit we will receive on the test data
profit <- function(pred, actual, loss, revenue){
  profit <- revenue-loss
  tmp <- sum(profit*pred[pred<actual])+sum((profit*actual-loss*(pred-actual))[actual<=pred])
  return(tmp)
}
```

How do we generate the prediction of 90% quantile of future sales? We use **Prediction interval!** The function `predict()` in `R` can achieve that with the additional argument `interval='prediction'` and `level`. The `level` argument specifies the confidence level of the prediction interval. Note that the prediction interval is two-sided, thus, to obtain the $q$ quantile of the predicted sales, we need to set the `level` argument as `level`=$1-2(1-q)$. In our case, $q=0.9$.

```{r, eval=F}
pred_interval_level <- 1-2*(1-0.9)
pred_opt <- exp(predict(lm_bwd, newdata=test_data, interval='prediction', level=pred_interval_level))-1
head(pred_opt)
```

Note that the `fit` column in `pred_opt` is the same as `pred_bwd`, which is the predicted mean of future sales given by the linear regression `lm_bwd`. The `upr` column in `pred_opt` gives the predicted 90% quantile of future sales. Let's evaluate the achieved profit and the forecasting error of the predicted mean and predicted 90% quantile of future sales on the test data.
```{r, eval=F}
# under stock probability in the test data
mean(pred_opt[,1]<test_data$sales)
mean(pred_opt[,3]<test_data$sales)

# Profit achieved in the test data
print(profit(pred=pred_opt[,1], actual=test_data$sales, loss=1, revenue=10))
print(profit(pred=pred_opt[,3], actual=test_data$sales, loss=1, revenue=10))

# Forecasting error achieved in the test data
print(accuracy(pred_opt[,1], test_data$sales))
print(accuracy(pred_opt[,3], test_data$sales))
```

Which prediction is more accurate? Which prediction is more profitable? Why is that?

We can further visualize the result to intuitively compare the predicted mean and predicted 90% quantile of future sales on the test data.
```{r, eval=F}
# Manually configure the C.I.
sample_time <- 1:60
plot(test_data$date[sample_time], test_data$sales[sample_time], xlab='', ylab='sales', ylim=c(100,600))
lines(test_data$date[sample_time], test_data$sales[sample_time])
lines(test_data$date[sample_time], pred_opt[sample_time,1], col='red')
lines(test_data$date[sample_time], pred_opt[sample_time,3], col='blue')
legend('topleft', c('actual','pred_mean','pred_opt'), lty=c(1,1,1), col=c('black','red','blue'), pch=c(1,NA,NA))
```


